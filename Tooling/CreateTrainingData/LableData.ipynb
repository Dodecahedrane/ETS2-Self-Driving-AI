{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import torchvision.models.segmentation\n",
    "import torch\n",
    "import torchvision.transforms as tf\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "widthSteering = heightSteering = 140\n",
    "\n",
    "widthRoad = 600\n",
    "heightRoad = 200\n",
    "\n",
    "modelsPath = 'Models'\n",
    "modelName = 'bestModel_dayOnly_MSEof6.4e-0.5.torch'\n",
    "pathToModel = f'{modelsPath}/{modelName}'\n",
    "\n",
    "framesPath = 'Frames'\n",
    "labeledFrames = 'LabeledFrames'\n",
    "wheelFrames = 'WheelFrames'\n",
    "\n",
    "#road crop area\n",
    "x1R = 400\n",
    "x2R = 600\n",
    "y1R = 630\n",
    "y2R = 1280\n",
    "\n",
    "#road image size\n",
    "widthRoad  = y2R - y1R\n",
    "heightRoad = x2R - x1R\n",
    "\n",
    "#wheel crop area\n",
    "x1W = 782\n",
    "x2W = 962\n",
    "y1W = 903\n",
    "y2W = 1043\n",
    "\n",
    "#wheel image size\n",
    "widthWheel  = y2W - y1W\n",
    "heightWheel = x2W-x1W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models Path Directoty Exists\n",
      "Frames Directoty Exists\n",
      "Labled Frames Directory Exists\n",
      "Wheel Frames Directory Exists\n"
     ]
    }
   ],
   "source": [
    "exist = os.path.exists(modelsPath)\n",
    "if exist:\n",
    "    print('Models Path Directoty Exists')\n",
    "else:\n",
    "    print('Directory Does not Exists')\n",
    "\n",
    "exist = os.path.exists(framesPath)\n",
    "if exist:\n",
    "    print(\"Frames Directoty Exists\")\n",
    "else:\n",
    "    print(\"Frames Directory Does Not Exists\")\n",
    "\n",
    "\n",
    "exist = os.path.exists(labeledFrames)\n",
    "if not exist:\n",
    "    os.makedirs(labeledFrames)\n",
    "    print(\"Labled Frames Directoty Created\")\n",
    "else:\n",
    "    print('Labled Frames Directory Exists')\n",
    "    #Uncomment these two lines if you want to delete the frames folder before adding more frames\n",
    "    #shutil.rmtree(labeledFrames)\n",
    "    #os.makedirs(labeledFrames)\n",
    "\n",
    "exist = os.path.exists(wheelFrames)\n",
    "if not exist:\n",
    "    os.makedirs(wheelFrames)\n",
    "    print(\"Wheel Frames Directoty Created\")\n",
    "else:\n",
    "    print('Wheel Frames Directory Exists')\n",
    "    #Uncomment these two lines if you want to delete the frames folder before adding more frames\n",
    "    #shutil.rmtree(labeledFrames)\n",
    "    #os.makedirs(labeledFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "startingFrames = [f for f in listdir(framesPath) if isfile(join(framesPath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(net, self).__init__()\n",
    "        self.fc = nn.Linear(512, 128)\n",
    "        \n",
    "        self.branch_a1 = nn.Linear(128, 32)\n",
    "        self.branch_a2 = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc(x))\n",
    "\n",
    "        a = F.leaky_relu(self.branch_a1(x))\n",
    "        \n",
    "        out1 = self.branch_a2(a)\n",
    "        \n",
    "        return out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load net\n",
    "#To Load Pretrained Weights:   weights='ResNet18_Weights.DEFAULT'\n",
    "resnet18 = torchvision.models.resnet18()\n",
    "resnet18.fc = nn.Identity()\n",
    "net_add=net()\n",
    "model = nn.Sequential(resnet18, net_add)\n",
    "\n",
    "# Set device GPU or CPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') \n",
    "\n",
    "# load model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(pathToModel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    i = 0\n",
    "    for file in startingFrames:\n",
    "        i=i+1\n",
    "        if i%100 == 0:\n",
    "            print(f'Frame No: {i}')\n",
    "        #dont want the '.jpg' element of the file name in the file name\n",
    "        noExtension = file[:-4]\n",
    "\n",
    "        filePath = f'{framesPath}/{file}'\n",
    "\n",
    "        #load image\n",
    "        wholeFrame = cv2.imread(filePath)\n",
    "\n",
    "        #crop to steering wheel logo and transform image to black and white but in RGB color space\n",
    "        crop = wholeFrame[x1W:x2W, y1W:y2W]\n",
    "\n",
    "        grayImage = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        (thresh, contrastImg) = cv2.threshold(grayImage, 100, 255, cv2.THRESH_BINARY)\n",
    "        backtorgb = cv2.cvtColor(contrastImg,cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        \n",
    "\n",
    "        transformImg=tf.Compose([tf.ToPILImage(),tf.Resize((heightWheel,widthWheel)),tf.ToTensor(),tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) \n",
    "        wheel=transformImg(np.array(backtorgb))\n",
    "\n",
    "        wheel = wheel.to(device).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            prediction = model(wheel)  # Run net\n",
    "\n",
    "        detectedAngle = prediction.data.cpu().numpy()[0][0]\n",
    "\n",
    "        realAngle = (180*detectedAngle)-90\n",
    "\n",
    "        cv2.imwrite(f'{wheelFrames}/wheelCrop_angleNorm_{detectedAngle}_angleReal_{realAngle}.jpg',backtorgb)\n",
    "\n",
    "        crop = wholeFrame[x1R:x2R, y1R:y2R]\n",
    "\n",
    "        cv2.imwrite(f'{labeledFrames}/{detectedAngle}_degrees_roadcrop_{noExtension}.jpg',crop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame No: 100\n",
      "Frame No: 200\n",
      "Frame No: 300\n",
      "Frame No: 400\n",
      "Frame No: 500\n",
      "Frame No: 600\n",
      "Frame No: 700\n",
      "Frame No: 800\n",
      "Frame No: 900\n",
      "Frame No: 1000\n",
      "Frame No: 1100\n",
      "Frame No: 1200\n",
      "Frame No: 1300\n",
      "Frame No: 1400\n",
      "Frame No: 1500\n",
      "Frame No: 1600\n",
      "Frame No: 1700\n",
      "Frame No: 1800\n",
      "Frame No: 1900\n",
      "Frame No: 2000\n",
      "Frame No: 2100\n",
      "Frame No: 2200\n",
      "Frame No: 2300\n",
      "Frame No: 2400\n",
      "Frame No: 2500\n",
      "Frame No: 2600\n",
      "Frame No: 2700\n",
      "Frame No: 2800\n",
      "Frame No: 2900\n",
      "Frame No: 3000\n",
      "Frame No: 3100\n",
      "Frame No: 3200\n",
      "Frame No: 3300\n",
      "Frame No: 3400\n",
      "Frame No: 3500\n",
      "Frame No: 3600\n",
      "Frame No: 3700\n",
      "Frame No: 3800\n",
      "Frame No: 3900\n",
      "Frame No: 4000\n",
      "Frame No: 4100\n",
      "Frame No: 4200\n",
      "Frame No: 4300\n",
      "Frame No: 4400\n",
      "Frame No: 4500\n",
      "Frame No: 4600\n",
      "Frame No: 4700\n",
      "Frame No: 4800\n",
      "Frame No: 4900\n",
      "Frame No: 5000\n",
      "Frame No: 5100\n",
      "Frame No: 5200\n",
      "Frame No: 5300\n",
      "Frame No: 5400\n",
      "Frame No: 5500\n",
      "Frame No: 5600\n",
      "Frame No: 5700\n",
      "Frame No: 5800\n",
      "Frame No: 5900\n",
      "Frame No: 6000\n",
      "Frame No: 6100\n",
      "Frame No: 6200\n",
      "Frame No: 6300\n",
      "Frame No: 6400\n",
      "Frame No: 6500\n",
      "Frame No: 6600\n",
      "Frame No: 6700\n",
      "Frame No: 6800\n",
      "Frame No: 6900\n",
      "Frame No: 7000\n",
      "Frame No: 7100\n",
      "Frame No: 7200\n",
      "Frame No: 7300\n",
      "Frame No: 7400\n",
      "Frame No: 7500\n",
      "Frame No: 7600\n",
      "Frame No: 7700\n",
      "Frame No: 7800\n",
      "Frame No: 7900\n",
      "Frame No: 8000\n",
      "Frame No: 8100\n",
      "Frame No: 8200\n",
      "Frame No: 8300\n",
      "Frame No: 8400\n",
      "Frame No: 8500\n",
      "Frame No: 8600\n",
      "Frame No: 8700\n",
      "Frame No: 8800\n",
      "Frame No: 8900\n",
      "Frame No: 9000\n",
      "Frame No: 9100\n",
      "Frame No: 9200\n",
      "Frame No: 9300\n",
      "Frame No: 9400\n",
      "Frame No: 9500\n",
      "Frame No: 9600\n",
      "Frame No: 9700\n",
      "Frame No: 9800\n",
      "Frame No: 9900\n",
      "Frame No: 10000\n",
      "Frame No: 10100\n",
      "Frame No: 10200\n",
      "Frame No: 10300\n",
      "Frame No: 10400\n",
      "Frame No: 10500\n",
      "Frame No: 10600\n",
      "Frame No: 10700\n",
      "Frame No: 10800\n",
      "Frame No: 10900\n",
      "Frame No: 11000\n",
      "Frame No: 11100\n",
      "Frame No: 11200\n",
      "Frame No: 11300\n",
      "Frame No: 11400\n",
      "Frame No: 11500\n",
      "Frame No: 11600\n",
      "Frame No: 11700\n",
      "Frame No: 11800\n",
      "Frame No: 11900\n",
      "Frame No: 12000\n",
      "Frame No: 12100\n",
      "Frame No: 12200\n",
      "Frame No: 12300\n",
      "Frame No: 12400\n",
      "Frame No: 12500\n",
      "Frame No: 12600\n",
      "Frame No: 12700\n",
      "Frame No: 12800\n",
      "Frame No: 12900\n",
      "Frame No: 13000\n",
      "Frame No: 13100\n",
      "Frame No: 13200\n",
      "Frame No: 13300\n",
      "Frame No: 13400\n",
      "Frame No: 13500\n",
      "Frame No: 13600\n",
      "Frame No: 13700\n",
      "Frame No: 13800\n",
      "Frame No: 13900\n",
      "Frame No: 14000\n",
      "Frame No: 14100\n",
      "Frame No: 14200\n",
      "Frame No: 14300\n",
      "Frame No: 14400\n",
      "Frame No: 14500\n",
      "Frame No: 14600\n",
      "Frame No: 14700\n",
      "Frame No: 14800\n",
      "Frame No: 14900\n",
      "Frame No: 15000\n",
      "Frame No: 15100\n",
      "Frame No: 15200\n",
      "Frame No: 15300\n",
      "Frame No: 15400\n",
      "Frame No: 15500\n",
      "Frame No: 15600\n",
      "Frame No: 15700\n",
      "Frame No: 15800\n",
      "Frame No: 15900\n",
      "Frame No: 16000\n",
      "Frame No: 16100\n",
      "Frame No: 16200\n",
      "Frame No: 16300\n",
      "Frame No: 16400\n",
      "Frame No: 16500\n",
      "Frame No: 16600\n",
      "Frame No: 16700\n",
      "Frame No: 16800\n",
      "Frame No: 16900\n",
      "Frame No: 17000\n",
      "Frame No: 17100\n",
      "Frame No: 17200\n",
      "Frame No: 17300\n",
      "Frame No: 17400\n",
      "Frame No: 17500\n",
      "Frame No: 17600\n",
      "Frame No: 17700\n",
      "Frame No: 17800\n",
      "Frame No: 17900\n",
      "Frame No: 18000\n",
      "Frame No: 18100\n",
      "Frame No: 18200\n",
      "Frame No: 18300\n",
      "Frame No: 18400\n",
      "Frame No: 18500\n",
      "Frame No: 18600\n",
      "Frame No: 18700\n",
      "Frame No: 18800\n",
      "Frame No: 18900\n",
      "Frame No: 19000\n",
      "Frame No: 19100\n",
      "Frame No: 19200\n",
      "Frame No: 19300\n",
      "Frame No: 19400\n",
      "Frame No: 19500\n",
      "Frame No: 19600\n",
      "Frame No: 19700\n",
      "Frame No: 19800\n",
      "Frame No: 19900\n",
      "Frame No: 20000\n",
      "Frame No: 20100\n",
      "Frame No: 20200\n",
      "Frame No: 20300\n",
      "Frame No: 20400\n",
      "Frame No: 20500\n",
      "Frame No: 20600\n",
      "Frame No: 20700\n",
      "Frame No: 20800\n",
      "Frame No: 20900\n",
      "Frame No: 21000\n",
      "Frame No: 21100\n",
      "Frame No: 21200\n",
      "Frame No: 21300\n",
      "Frame No: 21400\n",
      "Frame No: 21500\n",
      "Frame No: 21600\n",
      "Frame No: 21700\n",
      "Frame No: 21800\n",
      "Frame No: 21900\n",
      "Frame No: 22000\n",
      "Frame No: 22100\n",
      "Frame No: 22200\n",
      "Frame No: 22300\n",
      "Frame No: 22400\n",
      "Frame No: 22500\n",
      "Frame No: 22600\n",
      "Frame No: 22700\n",
      "Frame No: 22800\n",
      "Frame No: 22900\n",
      "Frame No: 23000\n",
      "Frame No: 23100\n",
      "Frame No: 23200\n",
      "Frame No: 23300\n",
      "Frame No: 23400\n",
      "Frame No: 23500\n",
      "Frame No: 23600\n",
      "Frame No: 23700\n",
      "Frame No: 23800\n",
      "Frame No: 23900\n",
      "Frame No: 24000\n",
      "Frame No: 24100\n",
      "Frame No: 24200\n",
      "Frame No: 24300\n",
      "Frame No: 24400\n",
      "Frame No: 24500\n",
      "Frame No: 24600\n",
      "Frame No: 24700\n",
      "Frame No: 24800\n",
      "Frame No: 24900\n",
      "Frame No: 25000\n",
      "Frame No: 25100\n",
      "Frame No: 25200\n",
      "Frame No: 25300\n",
      "Frame No: 25400\n",
      "Frame No: 25500\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
