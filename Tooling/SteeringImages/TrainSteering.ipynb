{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a649e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random\n",
    "from PIL import Image\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import time\n",
    "import numpy as np\n",
    "import torchvision.models.segmentation\n",
    "import torch\n",
    "import torchvision.transforms as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985cbb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Learning_Rate = 1e-3\n",
    "width = height = 80\n",
    "batchSize = 1024\n",
    "epochs = 200\n",
    "\n",
    "trainPercentage = 0.80\n",
    "testPercentage = 0.15\n",
    "valPercentage = 0.05 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f04beae",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87275e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'GeneratedImages'\n",
    "files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "#randomise the order of the files list\n",
    "random.shuffle(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cb6019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadRandomImg():\n",
    "    path = 'GeneratedImages/' + files[random.randrange(0,len(files))]\n",
    "    image = Image.open(path)\n",
    "    \n",
    "    s = path.split('_')[2]\n",
    "    angle = s[0:-7]\n",
    "\n",
    "    transformImg=tf.Compose([tf.ToPILImage(),tf.Resize((height,width)),tf.ToTensor(),tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) \n",
    "    image=transformImg(np.array(image))\n",
    "    return image, float(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec31f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadImg(name):\n",
    "    path = 'GeneratedImages/' + name\n",
    "    image = Image.open(path)\n",
    "    \n",
    "    s = path.split('_')[1]\n",
    "    angle = s[0:-7]\n",
    "    \n",
    "\n",
    "    transformImg=tf.Compose([tf.ToPILImage(),tf.Resize((height,width)),tf.ToTensor(),tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) \n",
    "    image=transformImg(np.array(image))\n",
    "    return image, float(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a54171",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFiles, valFiles, testFiles = np.split(files, [int(len(files)*trainPercentage), int(len(files)*trainPercentage) + int(len(files)*(testPercentage))])\n",
    "trainFiles = np.ndarray.tolist(trainFiles)\n",
    "trainFilesNotModified = trainFiles.copy()\n",
    "valFiles = np.ndarray.tolist(valFiles)\n",
    "testFiles = np.ndarray.tolist(testFiles)\n",
    "\n",
    "totalBatches = math.ceil(len(trainFiles)/batchSize)\n",
    "\n",
    "allBatches = []\n",
    "\n",
    "for i in range(0,totalBatches):\n",
    "    batch = []\n",
    "    for i in range(0,batchSize):\n",
    "        try:\n",
    "            fileName = trainFiles[0]\n",
    "            trainFiles.remove(fileName)\n",
    "        except:\n",
    "            fileName = files[random.randrange(0,len(files))]\n",
    "        batch.append(LoadImg(fileName))\n",
    "    \n",
    "    allBatches.append(batch)\n",
    "\n",
    "trainFiles = trainFilesNotModified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8636cac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadBatch(i):\n",
    "    images = torch.zeros([batchSize,3,height,width])\n",
    "    angles = torch.zeros([batchSize])\n",
    "    for j in range(0,batchSize):\n",
    "        images[j] = allBatches[i][j][0]\n",
    "        angles[j] = allBatches[i][j][1]\n",
    "    return images,angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e1c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mseTest(set, modelPath, partialSet = True, partialSetPer = 1):\n",
    "    \n",
    "    if set == 'test':\n",
    "        files = testFiles\n",
    "    elif(set == 'val'):\n",
    "        files = valFiles\n",
    "    elif(set == 'train'):\n",
    "        files = trainFiles\n",
    "    \n",
    "    if partialSet:\n",
    "        random.shuffle(files)\n",
    "        length = len(files)\n",
    "        files = files[0:int(length*partialSetPer)]\n",
    "\n",
    "    error = []\n",
    "\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    Net = torchvision.models.resnet50()\n",
    "    Net.fc = torch.nn.Linear(in_features=2048, out_features=1, bias=True)\n",
    "    Net = Net.to(device)\n",
    "\n",
    "    #modelPath = '19.torch'\n",
    "    Net.load_state_dict(torch.load(modelPath))\n",
    "\n",
    "    for file in files:\n",
    "        image, trueAngle = LoadImg(file)\n",
    "\n",
    "        Img = torch.autograd.Variable(image, requires_grad=False).to(device).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            Prd = Net(Img)  # Run net\n",
    "\n",
    "        predAngle = Prd.data.cpu().numpy()\n",
    "\n",
    "        error.append((trueAngle - predAngle)**2)\n",
    "\n",
    "    mse = (1/len(testFiles))*(sum(error))\n",
    "\n",
    "    #print(set + \" MSE: \", str(mse[0][0]))\n",
    "    return mse[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd46d144",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acc3d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------Load and set net and optimizer-------------------------------------\n",
    "\n",
    "# Set device GPU or CPU where the training will take place\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') \n",
    "\n",
    "#load net\n",
    "#weights='ResNet50_Weights.DEFAULT'\n",
    "Net = torchvision.models.resnet50()\n",
    "\n",
    "# Change final layer to predict one value\n",
    "Net.fc = torch.nn.Linear(in_features=2048, out_features=1, bias=True) \n",
    "\n",
    "Net = Net.to(device)\n",
    "\n",
    "# Create adam optimizer\n",
    "optimizer = torch.optim.Adam(params=Net.parameters(),lr=Learning_Rate) \n",
    "\n",
    "\n",
    "\n",
    "#----------------Train------------------------------------------------------------\n",
    "\n",
    "# Save average loss for display\n",
    "losses=np.zeros([epochs]) \n",
    "\n",
    "currentBatch = 0\n",
    "max = len(allBatches)*epochs\n",
    "\n",
    "mseAtEpochForVal = []\n",
    "mseAtEpochForTrain = []\n",
    "epochArr = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(0,epochs):\n",
    "    t = time.time()\n",
    "    for batch in range(0,len(allBatches)-1):\n",
    "        #print(\"Runing Batch: \" + str(batch) + \" on Epoch: \" + str(epoch))\n",
    "        \n",
    "        # Load taining batch\n",
    "        images,angle = LoadBatch(batch)\n",
    "        \n",
    "        # Load image\n",
    "        images=torch.autograd.Variable(images,requires_grad=False).to(device) \n",
    "        \n",
    "        # Load Ground truth fill level\n",
    "        angle = torch.autograd.Variable(angle, requires_grad=False).to(device) \n",
    "        \n",
    "        # make prediction\n",
    "        predLevel=Net(images)\n",
    "        Net.zero_grad()\n",
    "        Loss=torch.abs(predLevel-angle).mean()\n",
    "        \n",
    "        # Backpropogate loss\n",
    "        Loss.backward() \n",
    "        \n",
    "        # Apply gradient descent change to weight\n",
    "        optimizer.step() \n",
    "    \n",
    "    #val set MSE\n",
    "    mseAtEpochForVal.append(mseTest('val',modelPath))\n",
    "    mseAtEpochForTrain.append(mseTest('train',modelPath,partialSetPer = 0.05))\n",
    "    epochArr.append(epoch)\n",
    "\n",
    "    # Save loss average\n",
    "    losses[epoch]=Loss.data.cpu().numpy() \n",
    "\n",
    "    #Save model weight\n",
    "    modelPath = str(epoch) + \".torch\"\n",
    "    print(\"Saving Model: \" + modelPath) \n",
    "    torch.save(Net.state_dict(),   modelPath)  \n",
    "\n",
    "    elapsed = time.time() - t\n",
    "    print('Time To Run Epoch: ' + str(int(elapsed)) + ' Seconds')\n",
    "    print()\n",
    "\n",
    "    # Loss\n",
    "    #print(\"Epoch: \" + str(epoch) + \"   Loss=\",Loss.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b8b817",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochArr, losses, label='Loss')\n",
    "\n",
    "plt.title('Epoch vs Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a40903",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochArr, mseAtEpochForVal, label='Val Set')\n",
    "plt.plot(epochArr, mseAtEpochForTrain, label='Train Set')\n",
    "\n",
    "plt.title('Epoch vs MSE of Train and Val Sets')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
