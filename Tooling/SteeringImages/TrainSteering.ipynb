{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "79a649e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torchvision.models.segmentation\n",
    "import torch\n",
    "import torchvision.transforms as tf\n",
    "\n",
    "\n",
    "Learning_Rate=1e-5\n",
    "width=height=80 # image width and height\n",
    "batchSize=4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9f04beae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e03ea080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeneratedImages/edited1_frame0_108.30083565459609degrees_x-1_y-9crop.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'108.30083'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'GeneratedImages/' + files[random.randrange(0,len(files))]\n",
    "print(path)\n",
    "s = path.split('_')[2]\n",
    "s = s[0:-16]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "87275e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144001"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'GeneratedImages'\n",
    "files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "69cb6019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadRandomImg():\n",
    "    path = 'GeneratedImages/' + files[random.randrange(0,len(files))]\n",
    "    image = Image.open(path)\n",
    "    \n",
    "    s = path.split('_')[2]\n",
    "    angle = s[0:-7]\n",
    "\n",
    "    transformImg=tf.Compose([tf.ToPILImage(),tf.Resize((height,width)),tf.ToTensor(),tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) \n",
    "    image=transformImg(np.array(image))\n",
    "    return image, float(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8636cac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadBatch():\n",
    "    images = torch.zeros([batchSize,3,height,width])\n",
    "    angles = torch.zeros([batchSize])\n",
    "    for i in range(batchSize):\n",
    "        images[i],angles[i]=LoadRandomImg()\n",
    "    return images,angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2acc3d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ) Loss= 80.85829 AverageLoss 1.6171658325195313\n",
      "Saving Model0.torch\n",
      "1 ) Loss= 79.71418 AverageLoss 3.2114494323730467\n",
      "2 ) Loss= 80.71149 AverageLoss 4.825679168701172\n",
      "3 ) Loss= 82.60982 AverageLoss 6.477875518798828\n",
      "4 ) Loss= 80.09138 AverageLoss 8.079703063964844\n",
      "5 ) Loss= 80.73312 AverageLoss 9.69436553955078\n",
      "6 ) Loss= 80.57937 AverageLoss 11.305952911376954\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8321/344360951.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# Save loss average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mAverageLoss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\") Loss=\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'AverageLoss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAverageLoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Display loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#--------------Load and set net and optimizer-------------------------------------\n",
    "\n",
    "# Set device GPU or CPU where the training will take place\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') \n",
    "\n",
    "#load net\n",
    "Net = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# Change final layer to predict one value\n",
    "Net.fc = torch.nn.Linear(in_features=512, out_features=1, bias=True) \n",
    "\n",
    "Net = Net.to(device)\n",
    "\n",
    "# Create adam optimizer\n",
    "optimizer = torch.optim.Adam(params=Net.parameters(),lr=Learning_Rate) \n",
    "\n",
    "\n",
    "\n",
    "#----------------Train------------------------------------------------------------\n",
    "\n",
    "# Save average loss for display\n",
    "AverageLoss=np.zeros([50]) \n",
    "\n",
    "# Training loop\n",
    "for itr in range(500001): \n",
    "    # Load taining batch\n",
    "    images,GTFillLevel=LoadBatch()\n",
    "\n",
    "    # Load image\n",
    "    images=torch.autograd.Variable(images,requires_grad=False).to(device) \n",
    "    \n",
    "    # Load Ground truth fill level\n",
    "    GTFillLevel = torch.autograd.Variable(GTFillLevel, requires_grad=False).to(device) \n",
    "    \n",
    "    # make prediction\n",
    "    PredLevel=Net(images)\n",
    "    Net.zero_grad()\n",
    "    Loss=torch.abs(PredLevel-GTFillLevel).mean()\n",
    "    \n",
    "    # Backpropogate loss\n",
    "    Loss.backward() \n",
    "    \n",
    "    # Apply gradient descent change to weight\n",
    "    optimizer.step() \n",
    "    \n",
    "    # Save loss average\n",
    "    AverageLoss[itr%50]=Loss.data.cpu().numpy() \n",
    "    \n",
    "    print(itr,\") Loss=\",Loss.data.cpu().numpy(),'AverageLoss',AverageLoss.mean()) # Display loss\n",
    "    \n",
    "    # Save model\n",
    "    if itr % 200 == 0: \n",
    "        #Save model weight\n",
    "        print(\"Saving Model\" +str(itr) + \".torch\") \n",
    "        torch.save(Net.state_dict(),   str(itr) + \".torch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
