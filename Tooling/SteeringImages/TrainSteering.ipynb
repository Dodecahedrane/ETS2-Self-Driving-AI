{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79a649e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random\n",
    "from PIL import Image\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torchvision.models.segmentation\n",
    "import torch\n",
    "import torchvision.transforms as tf\n",
    "\n",
    "\n",
    "Learning_Rate=1e-5\n",
    "width=height=80 # image width and height\n",
    "batchSize=1024\n",
    "epochs = 60\n",
    "trainPercentage = 0.80\n",
    "testPercentage = 0.15\n",
    "valPercentage = 0.05 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f04beae",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87275e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'GeneratedImages'\n",
    "files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "#randomise the order of the files list\n",
    "random.shuffle(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cb6019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadRandomImg():\n",
    "    path = 'GeneratedImages/' + files[random.randrange(0,len(files))]\n",
    "    image = Image.open(path)\n",
    "    \n",
    "    s = path.split('_')[2]\n",
    "    angle = s[0:-7]\n",
    "\n",
    "    transformImg=tf.Compose([tf.ToPILImage(),tf.Resize((height,width)),tf.ToTensor(),tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) \n",
    "    image=transformImg(np.array(image))\n",
    "    return image, float(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec31f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadImg(name):\n",
    "    path = 'GeneratedImages/' + name\n",
    "    image = Image.open(path)\n",
    "    \n",
    "    s = path.split('_')[1]\n",
    "    angle = s[0:-7]\n",
    "\n",
    "    transformImg=tf.Compose([tf.ToPILImage(),tf.Resize((height,width)),tf.ToTensor(),tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) \n",
    "    image=transformImg(np.array(image))\n",
    "    return image, float(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53a54171",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFiles, valFiles, testFiles = np.split(files, [int(len(files)*trainPercentage), int(len(files)*trainPercentage) + int(len(files)*(testPercentage))])\n",
    "trainFiles = np.ndarray.tolist(trainFiles)\n",
    "trainFilesNotModified = trainFiles.copy()\n",
    "valFiles = np.ndarray.tolist(valFiles)\n",
    "testFiles = np.ndarray.tolist(testFiles)\n",
    "\n",
    "totalBatches = math.ceil(len(trainFiles)/batchSize)\n",
    "\n",
    "allBatches = []\n",
    "\n",
    "for i in range(0,totalBatches):\n",
    "    batch = []\n",
    "    for i in range(0,batchSize):\n",
    "        try:\n",
    "            fileName = trainFiles[0]\n",
    "            trainFiles.remove(fileName)\n",
    "        except:\n",
    "            fileName = files[random.randrange(0,len(files))]\n",
    "        batch.append(LoadImg(fileName))\n",
    "    \n",
    "    allBatches.append(batch)\n",
    "\n",
    "trainFiles = trainFilesNotModified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8636cac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadBatch(i):\n",
    "    images = torch.zeros([batchSize,3,height,width])\n",
    "    angles = torch.zeros([batchSize])\n",
    "    for j in range(0,batchSize):\n",
    "        images[j] = allBatches[i][j][0]\n",
    "        angles[j] = allBatches[i][j][1]\n",
    "    return images,angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49e1c54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  2175.2234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2175.2234"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def runTestOrValSet(set, modelPath, partialSet = True, partialSetPer = 0.2):\n",
    "    \n",
    "    if set == 'test':\n",
    "        files = testFiles\n",
    "    elif(set == 'val'):\n",
    "        files = valFiles\n",
    "    elif(set == 'train'):\n",
    "        files = trainFiles\n",
    "    \n",
    "    if partialSet:\n",
    "        random.shuffle(files)\n",
    "        length = len(files)\n",
    "        files = files[0:int(length*partialSetPer)]\n",
    "\n",
    "    error = []\n",
    "\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    Net = torchvision.models.resnet50(pretrained=True)\n",
    "    Net.fc = torch.nn.Linear(in_features=2048, out_features=1, bias=True)\n",
    "    Net = Net.to(device)\n",
    "\n",
    "    #modelPath = '19.torch'\n",
    "    Net.load_state_dict(torch.load(modelPath))\n",
    "\n",
    "    for file in files:\n",
    "        image, trueAngle = LoadImg(file)\n",
    "\n",
    "        Img = torch.autograd.Variable(image, requires_grad=False).to(device).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            Prd = Net(Img)  # Run net\n",
    "\n",
    "        predAngle = Prd.data.cpu().numpy()\n",
    "\n",
    "        error.append((trueAngle - predAngle)**2)\n",
    "\n",
    "    mse = (1/len(testFiles))*(sum(error))\n",
    "\n",
    "    print(set + \" MSE: \", str(mse[0][0]))\n",
    "    return mse[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd46d144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193552"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2acc3d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ) Loss= 46.204887 AverageLoss 0.9240977478027343\n",
      "Saving Model0.torch\n",
      "MSE:  1640.8268\n",
      "MSE:  2166.736\n",
      "1 ) Loss= 46.202152 AverageLoss 1.8481407928466798\n",
      "Saving Model1.torch\n",
      "MSE:  1638.7549\n",
      "MSE:  2160.893\n",
      "2 ) Loss= 46.19956 AverageLoss 2.7721319580078125\n",
      "Saving Model2.torch\n",
      "MSE:  1643.8856\n",
      "MSE:  2145.5554\n",
      "3 ) Loss= 46.196507 AverageLoss 3.6960620880126953\n",
      "Saving Model3.torch\n",
      "MSE:  1641.568\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_266886/1212371930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m#val set MSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mmseAtEpochForVal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunTestOrValSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodelPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mmseAtEpochForTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunTestOrValSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodelPath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpartialSetPer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mepochArr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_266886/3168558954.py\u001b[0m in \u001b[0;36mrunTestOrValSet\u001b[0;34m(set, modelPath, partialSet, partialSetPer)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mPrd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Run net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mpredAngle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1254\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_full_backward_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#--------------Load and set net and optimizer-------------------------------------\n",
    "\n",
    "# Set device GPU or CPU where the training will take place\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') \n",
    "\n",
    "#load net\n",
    "Net = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "# Change final layer to predict one value\n",
    "Net.fc = torch.nn.Linear(in_features=2048, out_features=1, bias=True) \n",
    "\n",
    "Net = Net.to(device)\n",
    "\n",
    "# Create adam optimizer\n",
    "optimizer = torch.optim.Adam(params=Net.parameters(),lr=Learning_Rate) \n",
    "\n",
    "\n",
    "\n",
    "#----------------Train------------------------------------------------------------\n",
    "\n",
    "# Save average loss for display\n",
    "AverageLoss=np.zeros([50]) \n",
    "\n",
    "currentBatch = 0\n",
    "max = len(allBatches)*epochs\n",
    "\n",
    "mseAtEpochForVal = []\n",
    "mseAtEpochForTrain = []\n",
    "epochArr = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(0,epochs):\n",
    "    for batch in range(0,len(allBatches)-1):\n",
    "        #print(\"Runing Batch: \" + str(batch) + \" on Epoch: \" + str(epoch))\n",
    "        \n",
    "        # Load taining batch\n",
    "        images,angle = LoadBatch(batch)\n",
    "        \n",
    "        # Load image\n",
    "        images=torch.autograd.Variable(images,requires_grad=False).to(device) \n",
    "        \n",
    "        # Load Ground truth fill level\n",
    "        angle = torch.autograd.Variable(angle, requires_grad=False).to(device) \n",
    "        \n",
    "        # make prediction\n",
    "        predLevel=Net(images)\n",
    "        Net.zero_grad()\n",
    "        Loss=torch.abs(predLevel-angle).mean()\n",
    "        \n",
    "        # Backpropogate loss\n",
    "        Loss.backward() \n",
    "        \n",
    "        # Apply gradient descent change to weight\n",
    "        optimizer.step() \n",
    "\n",
    "    # Save loss average\n",
    "    AverageLoss[epoch%50]=Loss.data.cpu().numpy() \n",
    "    \n",
    "    # Loss\n",
    "    print(epoch,\") Loss=\",Loss.data.cpu().numpy(),'AverageLoss',AverageLoss.mean())       \n",
    "\n",
    "    #Save model weight\n",
    "    modelPath = str(epoch) + \".torch\"\n",
    "    print(\"Saving Model\" + modelPath) \n",
    "    torch.save(Net.state_dict(),   modelPath)    \n",
    "\n",
    "    #val set MSE\n",
    "    mseAtEpochForVal.append(runTestOrValSet('val',modelPath))\n",
    "    mseAtEpochForTrain.append(runTestOrValSet('train',modelPath,partialSetPer = 0.05))\n",
    "    epochArr.append(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ced6b11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 4]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61d1994a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1640.8268, 1638.7549, 1643.8856, 1641.568]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mseAtEpochForVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab4703e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2166.736, 2160.893, 2145.5554, 2145.7894]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mseAtEpochForTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "56a40903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochArr, mseAtEpochForVal, label='Val Set')\n",
    "plt.plot(epochArr, mseAtEpochForTrain, label='Train Set')\n",
    "\n",
    "plt.title('Epoch vs MSE of Train and Val Sets')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
